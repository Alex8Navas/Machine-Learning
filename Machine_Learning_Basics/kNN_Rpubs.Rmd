---
title: "<div style='text-align:center;'>**Algoritmo k-Nearest Neighbors (kNN)**</div>"
author: "<div style='text-align:center;'>**Alejandro Navas González**</div>"
date: '<div style="text-align:center;"> **Fecha: `r format(Sys.Date(),"%e de %B, %Y")`** <div style="text-align:center;">' 
output:
  pdf_document:
    latex_engine: xelatex
    highlight: tango
    df_print: paged
    keep_tex: yes
    toc: yes
    toc_depth: 6
  html_document:
    df_print: paged
    toc: yes
    toc_depth: 6
    toc_float: true
    theme: spacelab
lang: en
nocite: |
  @lantz2015machine
params:
  file1: wisc_bc_data.csv
  folder.data: ./data
  p.train: 2/3
bibliography: ./data/pec1.BIB
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, message = FALSE, warning = FALSE, 
                      comment = NA, prompt = FALSE, tidy = FALSE)
```


## **Introducción: Nearest Neighbors**

<p style="text-align:justify;">
Los clasificadores nearest neighbor se definen por su carcaterística de clasificar ejemplos no etiquetados asignándoles la clase de aquellos ejemplos etiquetados que son más similares. A pesar de lo simple de esta propuesta, los métodos nearest neighbor son muy poderosos. De hecho, se ha empleado este método para:
</p>

- Aplicaciones de visión por ordenador, incluyendo reconocimiento óptico de caracteres y reconocimiento facial. 
- Predecir si una persona disfruta de una película que le han recomendado (Netflix). 
- Identificar patrones en los datos genéticos, para su uso en la detección de proteínas o enfermedades específicas. 

<p style="text-align:justify;">
Este método es útil cuando se trabaja con clases numerosas, complejas y que de otra forma serían muy difíciles de manejar, pero con el requisito que los elementos dentro de una clase son similares, de que existe homogeneidad y claridad de distinción entre los grupos. Por contra, si no se ofrece una clara diferencia entre grupos, este algoritmo no se recomienda. 
</p>

### **Algoritmo k-NN: Fortalezas y Debilidades**

Las fortalezas y debilidades de este algoritmo son:

| **Fortalezas** | **Debilidades** |
-- | --
| Simple y efectivo | No produce un modelo, lo que limita la habilidad de encontrar nuevas relaciones entre las variables objeto de estudio. |
| No realiza supuestos sobre una distribución subyacente de los datos | Su fase de clasificación es lenta.|
| Tiene una fase de entrenamiento rápida | Requiere de una gran cantidad de memoria.|
|   | Las variables nominales y los valores perdidos (NA) requieren de un procesamiento adicional. |

<p style="text-align:justify;">
Por último, como detalle a destacar, este algoritmo se dice que es vago o *lazy* porque, técnicamente hablando, no hay proceso de abstracción. Los procesos de abstracción y generalización ocurren simultáneamente. Esto permite que la fase de entrenamiento sea en extremo rápido, y conlleva la posible desventaja de que el proceso de predicción tienda a ser relativamente lento. Además, al basarse en casos concretos, no construye un modelo. Por ello se dice que el método se encuentra en una clase de **métodos de aprendizaje no paramétricos**, puesto que no se aprenden parámetros sobre los datos.
</p>

### **Cálculo de la Distancia**

<p style="text-align:justify;">
Para establecer el algoritmo k-NN se precisa de una función de distancias o una fórmula que permita medir la similaridad entre dos sujetos. Existen muchas formas de calcular las distancias. De forma tradicional, este algoritmo utiliza las **distancia euclídea**, que es una distancia que se daría uniendo mediante una regla dos puntos. Otra distancia habitual es la de **Manhattan**, que es aquella basada en los caminos que seguiría un peatón al caminar por las manzanas de la ciudad.
</p>

La **distancia euclídea** se especifica en la siguiente fórmula 

$$dist(p,q) = \sqrt{(p_1 − q_1)^2+(p_2 − q_2)^2+...+(p_n − q_n)^2}$$ 

### **Elección de la K**

<p style="text-align:justify;">
Elegir cuántos vecinos seleccionar en el k-NN determinará lo bien que el modelo se pueda utilizar para generalizar datos en un futuro. El balance entre el **_overfitting_** o **sobreajuste** y el **_underfitting_** o **infraajuste** del conjunto de datos de entrenamiento es un problema conocido como **bias-variance tradeoff**. Elegir un valor de k alto reduce el impacto o variación causada por el ruido del conjunto de datos, pero el sesgo o *bias* que se puede cometer entonces es ignorar pequeños, pero relevantes, patrones (*underfitting*), y viceversa, esto es, tomar un valor de k pequeño permitirá explorar detalles dentro del conjunto de datos pero no permitirá una generalización (*overfitting*). Esto se explica en la medida en que al fijar una k muy grande, póngase que igual al total número de observaciones en los datos de entrenamiento, como cada instancia de entrenamiento es representada en la votación final, la clase de entrenamiento más común siempre tiene la mayoría de los votantes. El modelo, por lo tanto, siempre predeciría la clase mayoritaria, independientemente de qué vecinos están más cerca. En el extremo opuesto, el uso de un solo vecino más cercano permite que datos ruidosos o valores atípicos puedan influir indebidamente en la clasificación de los sujetos. Por ejemplo, supóngase que algunos de los sujetos del marco de entrenamiento fueron accidentalmente mal etiquetados. Cualquier ejemplo no etiquetado que esté más cerca del vecino incorrectamente etiquetado se predecirá que pertenece a la clase incorrecta, incluso si los otros nueve vecinos más cercanos presentaran una clase diferente. Así pues, siempre convendrá encontrar el mejor k en algún punto entre ambos extremos.
</p>



## **Diagnóstico mediante kNN** 

<p style="text-align:justify;">
En este ejemplo se va a investigar la utilidad del Machine Learning para la detección del cáncer de mama aplicando un algoritmo k-NN a medidas de biopsisas de mujeres que presentaron masas anormales en los pechos.
</p>

### **Recolección de los Datos**

<p style="text-align:justify;">
Se utilizará el marco de datos de **Breast Cancer Wisconsin Diagnostic** del repositorio de la UCI para Machine Learning, el cual está disponible en el siguiente [**respositorio**](http://archive.ics.uci.edu/ml){target="_blank"}. Este conjunto de datos fue donado por investigadores de la [**Universidad de Wisconsin**](https://www.wisc.edu/){target="_blank"} y presenta medidas de imágenes digitales de masas extraídas de pecho. Este marco incluye un total de 569 biopsisas y 32 variables. Una de estas variables es el ID, otra el diagnóstico y las treinta restantes son medidas cuantitativas llevadas a cabo en laboratorio. El diagnóstico es tal que se utiliza **M** para indicar maligno y **B** para indicar beningno.
</p>

### **Exploración & Preparación**

En primer lugar, se importará el archivo csv con los datos de Wisconsin. 

```{r }
Wisc<-read.csv(file.path(params$folder.data, params$file1), stringsAsFactors = TRUE)

```

<p style="text-align:justify;">
A continuación, se estudiará la estructura del marco de datos, que habrá de contar con 569 observaciones y 32 variables.
</p>

```{r }

head(Wisc)
str(Wisc)

```

<p style="text-align:justify;">
La primera de las variabes es el ID o identificador único del paciente. Esta variable no aporta información útil, por lo que es preciso excluirla del modelo.
</p>

```{r }
# ID está en la primera columna. Se procede a su eliminación.
rownames(Wisc)<-Wisc[,1]
Wisc<-Wisc[, -1]
# Se comprueba que se ha eliminado la variable ID. 
head(Wisc)
str(Wisc)

```

<p style="text-align:justify;">
La variable *diagnosis* es de peculiar interés, ya que es aquello que se pretende predecir. Se puede ver cuántos sujetos tienen tumores beningnos frente a aquellos que tienen masas malignas. Por otro lado, muchos clasificadores de Machine Learning precisan de estar codificados como *factor*, por lo que es necesario también recodificar la variable *diagnosis* en caso de que no se presentara como *factor*. En esta situación dicha tarea se ha realizado al importar el marco de datos, si bien se añadirá este paso para generar etiquetas más informativas sobre los valores que puede tomar esta variable. 
</p>

```{r }
# Frecuencias absolutas. 
table(Wisc$diagnosis)
# Frecuencias relativas. 
prop.table(table(Wisc$diagnosis))
# Recodificación. 
Wisc$diagnosis<-factor(Wisc$diagnosis, levels = c("B", "M"), 
                        labels = c("Benigno", "Maligno"))
# Comprobación de la recodificación.
round(prop.table(table(Wisc$diagnosis)) * 100, digits = 1)
```

<p style="text-align:justify;">
El resto de variables son todas numéricas y consisten en tres medidas diferentes de diez características. Se van a estudiar detalladamente los estadísticos básicos de tres de ellas. 
</p> 

```{r }
summary(Wisc[c("radius_mean", "area_mean", "smoothness_mean")])

```

<p style="text-align:justify;">
Observando los resultados de estos estadísticos se tiene un problema, pues mientras que la media de *smoothness* va de 0.05 a 0.16, la media del área va de 143,5 a 2501.0, de modo que el impacto del área será muy superior al de *smoothness* al calcular las distancias. Por este motivo es preciso aplicar una normalización, para reescalar de las características a un rango estándar de valores. 
</p>

#### **Transformación. La Normalización de los Datos Numéricos**

<p style="text-align:justify;">
Para llevar a cabo la normalización es preciso crear una función en R que lo haga. Esta función tomará el conjunto de valores de un vector x y para cada valor en x, le restará el valor mínimo de x y lo dividirá por el rango de x. Finalmente, devolverá el vector resultante de la transformaión.
</p>

```{r }
# Se crea la función para normalizar. 
Normalizar<-function(x) {
return ((x - min(x)) / (max(x) - min(x)))
}
# Se aplica a las 30 variables cuantitativas. 
Wisc.Normalizado<-as.data.frame(lapply(Wisc[2:31], Normalizar))

# Se confirma que la normalización se ha efectuado correctamente. 
summary(Wisc.Normalizado$area_mean)
```

#### **Preparación de los Datos. Los Marcos de Entrenamiento & Prueba**

<p style="text-align:justify;">
En primer lugar, ante la ausencia de muestras cuyo status nos sea desconocido para testear el modelo, se va a simular dicho escenario mediante la división de nuestro marco en dos partes. Una de ellas, el conjunto de entrenamiento, será utilizada para crear el modelo kNN, y la otra, el conjunto de prueba o testeo, que será utilizado para ver la precisión predictiva del modelo creado. De los 569 sujetos, cien serán utilizados para el conjunto de testeo y 469 para el de entrenamiento.
</p>

```{r }
Wisc_train <- Wisc.Normalizado[1:469, ]
Wisc_test <- Wisc.Normalizado[470:569, ]

```

<p style="text-align:justify;">
Al construir estos marcos de datos se ha de excluir además la variable diana, la que se quiere explicar, séase, *diagnosis*. Para el entrenamiento del modelo kNN se almacenará esta variable como un vector de tipo factor, dividido según los marcos.
</p>

```{r }
Wisc_train_labels<-Wisc[1:469, 1]
Wisc_test_labels<-Wisc[470:569, 1]

```

### **Entrenamiento del Modelo**

<p style="text-align:justify;">
Para los algoritmos kNN, la fase de entrenamiento no involucra la creación del modelo, sino el almacenamiento de los datos de entrada en un formato estructurado. Para realizar la clasificación de nuestro marco de prueba, se utilizará una implementacioón kNN del paquete **class**. Concretamente la función *knn()* de este paquete ofrece una implementación estándar o clásica de un algoritmo kNN, utilizando las distancias euclídeas.
</p> 

<p style="text-align:justify;">
Con todo dispuesto, lo único que falta es especificar qué k es la apropiada. Como nuestro marco de entrenamiento ofrece 469 sujetos, se probará en primera instancia con un k=21, siendo 21 la raíz cuadrada de 469 si se truncan los decimales (realmente la raíz cuadrada de 469 es 21.656, pero dicho valor no se puede emplear como k). Por otro lado, usar un número impar reducirá la posibilidad de terminar con un voto de empate. Ahora, sí se está en disposición de aplicar el algoritmos kNN. 
</p>

```{r }
library(class)
Wisc_test_pred<-knn(train = Wisc_train, test = Wisc_test, cl = Wisc_train_labels, k=21)

```


### **Evaluación del Modelo**

<p style="text-align:justify;">
El próximo paso es la evaluación del modelo para saber cómo de bien las clases predichas en Wisc_test_pred se ajustan con los valores conocidos en Wisc_test_labels. Para realizar dicha evaluación se puede usar *CrossTable()*, una función del paquete **gmodels**.
</p> 

```{r }
library(gmodels)
CrossTable(x=Wisc_test_labels, y=Wisc_test_pred, prop.chisq = FALSE)

```

<p style="text-align:justify;">
Los resultados obtenidos indican lo siguiente. En la celda superior izquierda se tienen los verdaderos negativos. Se han obtenido 61 de 100 sujetos con masas benignas, y los kNN los han identificado como tal. En la celda inferior derecha se indican los verdaderos positivos, aquellos sujetos cuyos tumores se han identificados como malignos. Se han obtenido 37 verdaderos positivos. Los dos sujetos obtenidos en la parte inferior izquierda son falsos negativos, sujetos que se predice que tienen tumores benignos, pero realmente presentan tumores malignos. Los errores de esta clase son extremadamente peligrosos, ya que llevan al paciente a creer que no tiene cáncer cuando realmente éste avanza. Por otro lado, los sujetos de la celda superior derecha son los falsos positivos, que son aquellos sujetos clasificados como de tumores malignos cuando realmente su diagnóstico es benigno. En este caso no se han obtenido falsos positivos. A pesar de que este segundo tipo de error es menos peligroso que el del falso negativo, se ha evitar ya que supone un coste adicional, una carga para el sistema sanitario y/o un estrés adicional para el paciente. 
</p>

### **Mejora del Modelo**

<p style="text-align:justify;">
El resultado obtenido se puede mejorar y reducir la tasa de falsos negativos. Para ello se van a aplicar dos variaciones respecto del clasificador previo. Primero, se va a utilizar un método alternativo para reescalar las variables numéricas. Segundo, se utilizarán otros valores de k. 
</p>

#### **Transformación Alternativa: Estandarización por el Z-Score**

<p style="text-align:justify;">
Aunque la normalización es el método tradicional utilizado para la clasificación vía kNN, no siempre es la opción más apropiada. Al no predefinir un mínimo y un máximo, los valores estandarizados por el z-score no presentan valores extremos comprimidos hacia los valores centrales. Se puede pensar que para un tumor maligno es probable que se prersenten valores atípicos, pues el tumor crece descontroladamente, de tal modo que es razonable permitir que los valores atípicos pesen más en el cálculo de las distancias. Con este sistema de estandarización se puede comprobar si mejora la precisión del modelo. Para llevarla a cabo se recurre a la función scale(), que permite, por defecto, una estandarización vía z-score. Esta función permite trabajar sobre un data frame, de modo que no es necesaria la función lapply. 
</p>

```{r}

# Se estandafrizan todas las columnas menos la de diagnóstico. 
Wisc.Z<-as.data.frame(scale(Wisc[, -c(1)]))
# Se confirma la transformación. 
summary(Wisc.Z$area_mean)

```

<p style="text-align:justify;">
La media de una transfromación Z-score siempre ha de ser nula y el rango compacto. Un valor Z-score mayor que tres o menor que menos tres indica valores en extremo extraños. Se procede tras esta verificación a realizar dividir de nuevo el marco de datos en un set de prueba y otro de entrenamiento y en aplicar el algoritmo k-NN.
</p>


```{r }

Wisc_train.Z<-Wisc.Z[1:469, ]
Wisc_test.Z<-Wisc.Z[470:569, ]
# El paso de crear los vectores de etiquetas no es necesario, pues son los mismos. 
Wisc_test_pred.Z <- knn(train = Wisc_train.Z, test = Wisc_test.Z,
cl = Wisc_train_labels, k=21)
CrossTable(x = Wisc_test_labels, y = Wisc_test_pred.Z, prop.chisq=FALSE)

```

<p style="text-align:justify;">
Desafortunadamente, el resultado obtenido es una pérdida de precisión del test, han aumentado los falsos negativos, no se ha conseguido su mejora. 
</p>

#### **Valores Alternativos de K**

<p style="text-align:justify;">
Quizá se obtiene una mejora probando valores alternativos de k. Sobre esta base, recurriendo a los marcos de datos de prueba y entrenamiento normalizados, se aplican a continuación diferentes valores de k. 
</p>


```{r }

Wisc_test_pred.1<-knn(train = Wisc_train, test = Wisc_test, cl = Wisc_train_labels, k=1)
CrossTable(x=Wisc_test_labels, y=Wisc_test_pred.1, prop.chisq = FALSE)

Wisc_test_pred.5<-knn(train = Wisc_train, test = Wisc_test, cl = Wisc_train_labels, k=5)
CrossTable(x=Wisc_test_labels, y=Wisc_test_pred.5, prop.chisq = FALSE)

Wisc_test_pred.11<-knn(train = Wisc_train, test = Wisc_test, cl = Wisc_train_labels, k=11)
CrossTable(x=Wisc_test_labels, y=Wisc_test_pred.11, prop.chisq = FALSE)

Wisc_test_pred.15<-knn(train = Wisc_train, test = Wisc_test, cl = Wisc_train_labels, k=15)
CrossTable(x=Wisc_test_labels, y=Wisc_test_pred.15, prop.chisq = FALSE)

Wisc_test_pred.27<-knn(train = Wisc_train, test = Wisc_test, cl = Wisc_train_labels, k=27)
CrossTable(x=Wisc_test_labels, y=Wisc_test_pred.27, prop.chisq = FALSE)

```

<p style="text-align:justify;">
A pesar de que el clasificador en ningún caso es perfecto, el enfoque 1NN es capaz de evitar uno de los dos falsos negativos a expensas de introducir tres falsos positivos. Sin embargo, es importante tener en cuenta que no sería prudente adaptar el enfoque demasiado a la evaluación del rendimiento sobre el marco de prueba y tomar el 1NN a la ligera, pues es probable que un conjunto diferente de 100 registros de pacientes sea algo distinto de los que se utilizan para medir el rendimiento de nuestro modelo, es decir, es más que probable que al optar por un valor de k de uno se esté pecando de sobreajuste a los datos del set empleado para la evaluación. 
</p>

## **Bibliografía**